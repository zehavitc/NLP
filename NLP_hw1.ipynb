{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of NLP_hw1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zehavitc/NLP_Hw1/blob/master/NLP_hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lWiaqpj12oCc",
        "colab_type": "code",
        "outputId": "aedc74ae-e2c2-48e4-b1db-a93b09ce3de4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z-ligGo24C8c",
        "colab_type": "code",
        "outputId": "ab036293-b84c-4578-9ad8-5e7c7c4ed74a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive/NLP/HW1'"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en.csv\tfr.csv\tit.csv\tout.txt  tl.csv\n",
            "es.csv\tin.csv\tnl.csv\tpt.csv\t ZehavitTextTest.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rNDTpaxy4M1J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "import csv\n",
        "import math\n",
        "\n",
        "g_startTag = \"<s>\"\n",
        "g_endTag = \"</s>\"\n",
        "\n",
        "def _update_grams(text, n_gram, n_counts): \n",
        "    #print(f'n_gram is {n_gram}')\n",
        "    text = text.replace('\\n', ' ')\n",
        "    for i in range(0, len(text) - n_gram + 1):\n",
        "      #print(f'i is {i}')\n",
        "      t = text[i:i+n_gram-1]\n",
        "      #print(t)\n",
        "      n_char = text[i+n_gram-1]\n",
        "      #print(n_char)\n",
        "      n_counts[t][n_char] += 1\n",
        "    #handle start and end of tweet \n",
        "    if n_gram == 1:\n",
        "      n_counts[''][g_startTag] += 1\n",
        "      n_counts[''][g_endTag] += 1\n",
        "    if n_gram == 2:\n",
        "      n_counts[g_startTag][text[0]] += 1\n",
        "      n_counts[text[len(text)-1]][g_endTag] += 1 \n",
        "    if n_gram > 2:\n",
        "      n_counts[f'{g_startTag}{text[0]}'][text[n_gram -2]] += 1\n",
        "      n_counts[f'{text[len(text) - n_gram + 1: len(text)]}'][g_endTag] += 1\n",
        "      \n",
        "def _output_model_to_file(n_counts, model_file_path):\n",
        "    with open(model_file_path, \"w\") as model_file:\n",
        "      counter_1gram = n_counts[0]['']\n",
        "      counter_2gram = n_counts[1]\n",
        "      counter_3gram = n_counts[2]\n",
        "      \n",
        "      #output 3-gram \n",
        "      print(f\"3-grams:\", file=model_file)\n",
        "      trigramKeys = list(counter_3gram.keys())\n",
        "      for tk in trigramKeys:\n",
        "        #print(f'tk is: {tk}, len of tk is {len(tk)}')\n",
        "        trigramValues = list(counter_3gram[tk].keys())\n",
        "        if tk.startswith(g_startTag):\n",
        "          firstChar = g_startTag\n",
        "          secondChar = tk[3]\n",
        "        elif tk.endswith(g_endTag):\n",
        "          firstChar = tk[0]\n",
        "          secondChar = g_endTag\n",
        "        else:\n",
        "          firstChar = tk[0]\n",
        "          secondChar = tk[1]\n",
        "        charsCount = counter_2gram[firstChar][secondChar]\n",
        "        #print(f'chars count of {firstChar} {secondChar} is {charsCount}')\n",
        "        for v in trigramValues:\n",
        "          #print(f'v is: {v}')\n",
        "          print(f'<{firstChar}><{secondChar}><{v}>\\t{counter_3gram[tk][v]/charsCount}', file=model_file)\n",
        "          #print(f'<{firstChar}><{secondChar}><{v}>\\t{math.log(counter_3gram[tk][v]/charsCount, 2)}', file=model_file)\n",
        "      print(\"\", file=model_file)    \n",
        "      \n",
        "      #output 2-gram\n",
        "      print(f\"2-grams:\", file=model_file)\n",
        "      bigramKeys = list(counter_2gram.keys())\n",
        "      for bk in bigramKeys:\n",
        "        bigramValues = list(counter_2gram[bk].keys())\n",
        "        charsCount = counter_1gram[bk]\n",
        "        for v in  bigramValues:\n",
        "          print(f'<{bk}><{v}>\\t{counter_2gram[bk][v]/charsCount}', file=model_file) \n",
        "          #print(f'<{bk}><{v}>\\t{math.log(counter_2gram[bk][v]/charsCount, 2)}', file=model_file) \n",
        "      print(\"\", file=model_file)     \n",
        "      \n",
        "      #output 1-gram\n",
        "      print(f\"1-grams:\", file=model_file)\n",
        "      unigramKeys = list(counter_1gram.keys())\n",
        "      charsCount = sum(list(counter_1gram.values()))\n",
        "      for k in unigramKeys:\n",
        "        print(f'<{k}>\\t{counter_1gram[k]/charsCount}', file=model_file)\n",
        "        #print(f'<{k}>\\t{math.log(counter_1gram[k]/charsCount, 2)}', file=model_file)\n",
        "      print(\"\", file=model_file)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In: corpus_file_path: a csv corpus file path - each line is a <TweetID>,<TweetText> \n",
        "# Out: model_file_path: model_file \n",
        "def\tlm(corpus_file_path,\tmodel_file_path):\n",
        "  with open(corpus_file_path, 'r') as corpus_file:\n",
        "    reader = csv.DictReader(corpus_file)\n",
        "    #unigram, bigram, trigram\n",
        "    n_counts = [defaultdict(Counter), defaultdict(Counter), defaultdict(Counter)]\n",
        "    for row in reader:\n",
        "      tweet_text = row[\"tweet_text\"]   \n",
        "      #print(tweet_text)\n",
        "      for i in range(1,4):       \n",
        "        _update_grams(tweet_text, i, n_counts[i-1])  \n",
        "      \n",
        "    _output_model_to_file(n_counts, model_file_path)\n",
        "  print('lm done')\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-nhzM_Lhc3Pp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "from collections import namedtuple\n",
        "from collections import Counter, defaultdict\n",
        "import math\n",
        "import sys\n",
        "\n",
        "bigram_key = namedtuple('bigram_key', [\"first\"])\n",
        "trigram_key = namedtuple(\"trigram_key\", [\"first\", \"second\"])\n",
        "\n",
        "\n",
        "\n",
        "def eval(input_file, model_file, weights):\n",
        "  trigram_model, bigram_model, unigram_model = parse(model_file)\n",
        "  with open(input_file, 'r') as input_file:\n",
        "    reader = csv.DictReader(input_file)\n",
        "    #unigram, bigram, trigram\n",
        "    total_len = 0\n",
        "    p_interp_list = []\n",
        "    for row in reader:\n",
        "      tweet_text = row[\"tweet_text\"].replace('\\n', ' ')\n",
        "      total_len += (len(tweet_text) + 2)\n",
        "  #     print(tweet_text)    \n",
        "      for i in range(len(tweet_text)):\n",
        "        if i==0:\n",
        "            p_interp =  (weights[1]*bigram_model[bigram_key(first = g_startTag)][tweet_text[i]]) + \\\n",
        "                        (weights[2]*unigram_model[tweet_text[i]])           \n",
        "        elif i==1:\n",
        "            p_interp = (weights[0]*trigram_model[trigram_key(first = g_startTag, second = tweet_text[i-1])][tweet_text[i]]) + \\\n",
        "                       (weights[1]*bigram_model[bigram_key(first = tweet_text[i-1])][tweet_text[i]]) + \\\n",
        "                       (weights[2]*unigram_model[tweet_text[i]]) \n",
        "        else:\n",
        "          p_interp = (weights[0]*trigram_model[trigram_key(first = tweet_text[i-2], second = tweet_text[i-1])][tweet_text[i]]) + \\\n",
        "                     (weights[1]*bigram_model[bigram_key(first = tweet_text[i-1])][tweet_text[i]]) + \\\n",
        "                     (weights[2]*unigram_model[tweet_text[i]])     \n",
        "        p_interp_list.append(float(p_interp))\n",
        "      #handle closing tag, assuming no empty tweet\n",
        "      p_trigram = trigram_model[trigram_key(first = g_startTag, second = tweet_text[len(tweet_text)-1])][g_endTag] if len(tweet_text) == 1 else trigram_model[trigram_key(first = tweet_text[len(tweet_text) - 2], second = tweet_text[len(tweet_text)-1])][g_endTag]\n",
        "      p_interp_closing = (weights[0]*p_trigram) + \\\n",
        "                   (weights[1]*(bigram_model[bigram_key(first = tweet_text[len(tweet_text)-1])][g_endTag])) + \\\n",
        "                   (weights[2]*(unigram_model[g_endTag])) \n",
        "      p_interp_list.append(float(p_interp_closing))\n",
        "    #calc entropy \n",
        "    log_sum = sum([(math.log(v,2) if v != 0  else sys.float_info.min) for v in p_interp_list])\n",
        "    entropy = -log_sum / total_len\n",
        "    return math.pow(2,entropy)\n",
        "    \n",
        "  \n",
        "def parse(model_file):\n",
        "  with open(model_file) as model:\n",
        "    # Skips text before the beginning of the interesting block:\n",
        "    for line in model:\n",
        "        if line.strip() == '3-grams:':  # Or whatever test is needed\n",
        "            break\n",
        "    # Reads text until the end of the block:\n",
        "    trigram_model = defaultdict(Counter)\n",
        "\n",
        "    for line in model:  # This keeps reading the file\n",
        "        if line.strip() == '':\n",
        "            break\n",
        "        #print(line)  # Line is extracted (or block_of_lines.append(line), etc.)\n",
        "        match = re.search(\"<(.*)><(.*)><(.*)>\\t(.*)\", line)\n",
        "        #print(f'grpup 1 is: {match.group(1)}')\n",
        "        #print(f'grpup 2 is: {match.group(2)}')\n",
        "        #print(line)\n",
        "        k = trigram_key(first=match.group(1), second=match.group(2))\n",
        "        #print(f'key is {k}')\n",
        "        trigram_model[k][match.group(3)] = float(match.group(4))\n",
        "    \n",
        "    for line in model:\n",
        "      if line.strip() =='2-grams:':\n",
        "        break;\n",
        "    bigram_model = defaultdict(Counter)\n",
        "    for line in model:  # This keeps reading the file\n",
        "      if line.strip() == '':\n",
        "          break\n",
        "#       print(line)  # Line is extracted (or block_of_lines.append(line), etc.)\n",
        "      match = re.search(\"<(.*)><(.*)>\\t(.*)\", line)\n",
        "      #print(f'grpup 1 is: {match.group(1)}')\n",
        "      #print(f'grpup 2 is: {match.group(2)}')\n",
        "      k = bigram_key(first=match.group(1))\n",
        "      #print(f'key is {k}')\n",
        "      bigram_model[k][match.group(2)] = float(match.group(3))\n",
        "\n",
        "    # print(bigram_model)\n",
        "    \n",
        "    for line in model:\n",
        "      if line.strip() =='1-grams:':\n",
        "#         print(line)\n",
        "        break;\n",
        "    unigram_model = defaultdict(float)\n",
        "    for line in model:  # This keeps reading the file\n",
        "      if line.strip() == '':\n",
        "          break\n",
        "#       print(line)  # Line is extracted (or block_of_lines.append(line), etc.)\n",
        "      match = re.search(\"<(.*)>\\t(.*)\", line)\n",
        "      #print(f'grpup 1 is: {match.group(1)}')\n",
        "      #print(f'grpup 2 is: {match.group(2)}')\n",
        "      #print(f'key is {k}')\n",
        "      unigram_model[match.group(1)] = float(match.group(2))\n",
        "\n",
        "    #print(unigram_model)\n",
        "    return (trigram_model, bigram_model, unigram_model)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lm9JM0ZghgOv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!rm '/content/drive/My Drive/NLP/HW1/out.txt'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4yD7zb8PZZd9",
        "colab_type": "code",
        "outputId": "2915443c-6e99-4d24-cc15-72998f8f75e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#corpus_file_path = '/content/drive/My Drive/NLP/HW1/en.csv'\n",
        "#model_file_path =  '/content/drive/My Drive/NLP/HW1/out.txt'\n",
        "#lm(corpus_file_path, model_file_path)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lm done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hksnnU-OzdVj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c855957b-bc54-45ed-a2f7-a47c8e2a515f"
      },
      "cell_type": "code",
      "source": [
        "#eval('/content/drive/My Drive/NLP/HW1/es.csv', '/content/drive/My Drive/NLP/HW1/out.txt', [0.4,0.3,0.3])"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20.085902692255633"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "metadata": {
        "id": "W77J_h48YnN9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 434
        },
        "outputId": "6ecc71ab-ab07-4b7d-fc01-edbac7bb4a4b"
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd \n",
        "\n",
        "\n",
        "def _get_path_for_name(name):\n",
        "  return f'/content/drive/My Drive/NLP/HW1/{name}.csv'\n",
        "\n",
        "langs  = ['en', 'es', 'fr', 'in', 'it', 'nl', 'pt', 'tl']\n",
        "#langs  = ['en', 'es']\n",
        "files = [_get_path_for_name(l) for l in langs]\n",
        "weights = [0.4,0.3,0.3]\n",
        "\n",
        "def identify_lang():\n",
        "  #results = [langs.copy()]\n",
        "  #results[0].insert(0, ' ')\n",
        "  results = []\n",
        "  \n",
        "  for l in langs:\n",
        "    df = pd.read_csv(_get_path_for_name(l), encoding='ISO-8859-1')\n",
        "    train = df.sample(frac=0.9)\n",
        "    train_path = _get_path_for_name(f'{l}_train.csv')\n",
        "    model_path = _get_path_for_name(f'{l}_model.txt')\n",
        "    df.to_csv(train_path)\n",
        "    lm(train_path, model_path)\n",
        "    lang_results = []\n",
        "    for l in langs:\n",
        "      lang_results.append(eval(_get_path_for_name(l), model_path, weights))\n",
        "    results.append(lang_results)\n",
        "    \n",
        "  return pd.DataFrame(results, langs, langs)\n",
        "\n",
        "identify_lang()"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "lm done\n",
            "lm done\n",
            "lm done\n",
            "lm done\n",
            "lm done\n",
            "lm done\n",
            "lm done\n",
            "lm done\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>en</th>\n",
              "      <th>es</th>\n",
              "      <th>fr</th>\n",
              "      <th>in</th>\n",
              "      <th>it</th>\n",
              "      <th>nl</th>\n",
              "      <th>pt</th>\n",
              "      <th>tl</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>en</th>\n",
              "      <td>12.098403</td>\n",
              "      <td>19.856888</td>\n",
              "      <td>20.710524</td>\n",
              "      <td>21.527680</td>\n",
              "      <td>18.873814</td>\n",
              "      <td>19.650246</td>\n",
              "      <td>21.405984</td>\n",
              "      <td>19.754943</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>es</th>\n",
              "      <td>20.280610</td>\n",
              "      <td>12.258516</td>\n",
              "      <td>18.329501</td>\n",
              "      <td>23.174260</td>\n",
              "      <td>16.846648</td>\n",
              "      <td>21.814565</td>\n",
              "      <td>16.906084</td>\n",
              "      <td>21.802658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fr</th>\n",
              "      <td>18.971111</td>\n",
              "      <td>17.475795</td>\n",
              "      <td>13.762360</td>\n",
              "      <td>23.185811</td>\n",
              "      <td>18.488773</td>\n",
              "      <td>20.702984</td>\n",
              "      <td>19.714554</td>\n",
              "      <td>22.491690</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>in</th>\n",
              "      <td>19.568051</td>\n",
              "      <td>20.673424</td>\n",
              "      <td>24.112045</td>\n",
              "      <td>12.776977</td>\n",
              "      <td>20.395312</td>\n",
              "      <td>21.110217</td>\n",
              "      <td>22.342062</td>\n",
              "      <td>18.037316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>it</th>\n",
              "      <td>19.911945</td>\n",
              "      <td>17.150583</td>\n",
              "      <td>18.068464</td>\n",
              "      <td>23.172832</td>\n",
              "      <td>11.570243</td>\n",
              "      <td>22.167298</td>\n",
              "      <td>18.074792</td>\n",
              "      <td>20.455094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nl</th>\n",
              "      <td>18.163060</td>\n",
              "      <td>19.627426</td>\n",
              "      <td>19.137466</td>\n",
              "      <td>21.538902</td>\n",
              "      <td>20.282337</td>\n",
              "      <td>12.348462</td>\n",
              "      <td>21.182268</td>\n",
              "      <td>20.649026</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pt</th>\n",
              "      <td>20.703215</td>\n",
              "      <td>16.216116</td>\n",
              "      <td>18.857026</td>\n",
              "      <td>23.698860</td>\n",
              "      <td>17.468701</td>\n",
              "      <td>22.737250</td>\n",
              "      <td>12.255169</td>\n",
              "      <td>21.376160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tl</th>\n",
              "      <td>18.016843</td>\n",
              "      <td>19.488982</td>\n",
              "      <td>23.998614</td>\n",
              "      <td>18.694047</td>\n",
              "      <td>19.571747</td>\n",
              "      <td>21.809845</td>\n",
              "      <td>21.089908</td>\n",
              "      <td>11.420352</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           en         es         fr         in         it         nl  \\\n",
              "en  12.098403  19.856888  20.710524  21.527680  18.873814  19.650246   \n",
              "es  20.280610  12.258516  18.329501  23.174260  16.846648  21.814565   \n",
              "fr  18.971111  17.475795  13.762360  23.185811  18.488773  20.702984   \n",
              "in  19.568051  20.673424  24.112045  12.776977  20.395312  21.110217   \n",
              "it  19.911945  17.150583  18.068464  23.172832  11.570243  22.167298   \n",
              "nl  18.163060  19.627426  19.137466  21.538902  20.282337  12.348462   \n",
              "pt  20.703215  16.216116  18.857026  23.698860  17.468701  22.737250   \n",
              "tl  18.016843  19.488982  23.998614  18.694047  19.571747  21.809845   \n",
              "\n",
              "           pt         tl  \n",
              "en  21.405984  19.754943  \n",
              "es  16.906084  21.802658  \n",
              "fr  19.714554  22.491690  \n",
              "in  22.342062  18.037316  \n",
              "it  18.074792  20.455094  \n",
              "nl  21.182268  20.649026  \n",
              "pt  12.255169  21.376160  \n",
              "tl  21.089908  11.420352  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    }
  ]
}