{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_hw1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zehavitc/NLP_Hw1/blob/master/NLP_hw1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "lWiaqpj12oCc",
        "colab_type": "code",
        "outputId": "d514fec3-2395-46c5-dc34-1a9024bc577f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "z-ligGo24C8c",
        "colab_type": "code",
        "outputId": "fcb59625-98cc-4e4e-f9dc-d9e344238741",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "!ls '/content/drive/My Drive/NLP/HW1'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "en.csv\tfr.csv\tit.csv\tout.txt  tl.csv\n",
            "es.csv\tin.csv\tnl.csv\tpt.csv\t ZehavitTextTest.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rNDTpaxy4M1J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from collections import Counter, defaultdict\n",
        "import csv\n",
        "import math\n",
        "\n",
        "g_startTag = \"<s>\"\n",
        "g_endTag = \"</s>\"\n",
        "\n",
        "def _update_grams(text, n_gram, n_counts): \n",
        "    #print(f'n_gram is {n_gram}')\n",
        "    for i in range(0, len(text) - n_gram + 1):\n",
        "      #print(f'i is {i}')\n",
        "      t = text[i:i+n_gram-1]\n",
        "      #print(t)\n",
        "      n_char = text[i+n_gram-1]\n",
        "      #print(n_char)\n",
        "      n_counts[t][n_char] += 1\n",
        "    #handle start and end of tweet \n",
        "    if n_gram == 1:\n",
        "      n_counts[''][g_startTag] += 1\n",
        "      n_counts[''][g_endTag] += 1\n",
        "    if n_gram == 2:\n",
        "      n_counts[g_startTag][text[0]] += 1\n",
        "      n_counts[text[len(text)-1]][g_endTag] += 1 \n",
        "    if n_gram > 2:\n",
        "      n_counts[f'{g_startTag}{text[0]}'][text[n_gram -2]] += 1\n",
        "      n_counts[f'{text[len(text) - n_gram + 1: len(text)]}'][g_endTag] += 1\n",
        "      \n",
        "def _output_model_to_file(n_counts, model_file_path):\n",
        "    with open(model_file_path, \"w\") as model_file:\n",
        "      counter_1gram = n_counts[0]['']\n",
        "      counter_2gram = n_counts[1]\n",
        "      counter_3gram = n_counts[2]\n",
        "      \n",
        "      #output 3-gram \n",
        "      print(f\"3-grams:\", file=model_file)\n",
        "      trigramKeys = list(counter_3gram.keys())\n",
        "      for tk in trigramKeys:\n",
        "        #print(f'tk is: {tk}, len of tk is {len(tk)}')\n",
        "        trigramValues = list(counter_3gram[tk].keys())\n",
        "        if tk.startswith(g_startTag):\n",
        "          firstChar = g_startTag\n",
        "          secondChar = tk[3]\n",
        "        elif tk.endswith(g_endTag):\n",
        "          firstChar = tk[0]\n",
        "          secondChar = g_endTag\n",
        "        else:\n",
        "          firstChar = tk[0]\n",
        "          secondChar = tk[1]\n",
        "        charsCount = counter_2gram[firstChar][secondChar]\n",
        "        #print(f'chars count of {firstChar} {secondChar} is {charsCount}')\n",
        "        for v in trigramValues:\n",
        "          #print(f'v is: {v}')\n",
        "          print(f'<{firstChar}><{secondChar}><{v}>\\t{math.log(counter_3gram[tk][v]/charsCount, 2)}', file=model_file)\n",
        "      print(\"\", file=model_file)    \n",
        "      \n",
        "      #output 2-gram\n",
        "      print(f\"2-grams:\", file=model_file)\n",
        "      bigramKeys = list(counter_2gram.keys())\n",
        "      for bk in bigramKeys:\n",
        "        bigramValues = list(counter_2gram[bk].keys())\n",
        "        charsCount = counter_1gram[bk]\n",
        "        for v in  bigramValues:\n",
        "          print(f'<{bk}><{v}>\\t{math.log(counter_2gram[bk][v]/charsCount, 2)}', file=model_file) \n",
        "      print(\"\", file=model_file)     \n",
        "      \n",
        "      #output 1-gram\n",
        "      print(f\"1-grams:\", file=model_file)\n",
        "      unigramKeys = list(counter_1gram.keys())\n",
        "      charsCount = sum(list(counter_1gram.values()))\n",
        "      for k in unigramKeys:\n",
        "        print(f'<{k}>\\t{math.log(counter_1gram[k]/charsCount, 2)}', file=model_file)\n",
        "      print(\"\", file=model_file)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In: corpus_file_path: a csv corpus file path - each line is a <TweetID>,<TweetText> \n",
        "# Out: model_file_path: model_file \n",
        "def\tlm(corpus_file_path,\tmodel_file_path):\n",
        "  with open(corpus_file_path, 'r') as corpus_file:\n",
        "    reader = csv.DictReader(corpus_file)\n",
        "    #unigram, bigram, trigram\n",
        "    n_counts = [defaultdict(Counter), defaultdict(Counter), defaultdict(Counter)]\n",
        "    for row in reader:\n",
        "      tweet_text = row[\"tweet_text\"]   \n",
        "      print(tweet_text)\n",
        "      for i in range(1,4):       \n",
        "        _update_grams(tweet_text, i, n_counts[i-1])  \n",
        "      \n",
        "    _output_model_to_file(n_counts, model_file_path)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4yD7zb8PZZd9",
        "colab_type": "code",
        "outputId": "1971ada3-7680-42c4-f9f0-6201babb772f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "corpus_file_path = '/content/drive/My Drive/NLP/HW1/ZehavitTextTest.csv'\n",
        "model_file_path = '/content/drive/My Drive/NLP/HW1/out.txt'\n",
        "lm(corpus_file_path, model_file_path)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RT @HannahMemories1: This was not only catchy but helpful on my school days #11YearsOfHannahMontana https://t.co/Hd9FRilrAZ\n",
            "RT @Amour_essie: To argue w me is $250 posting subs $150 to fight me $800.   Now due to the fact that u bitches is broke there shouldn't beâ€¦\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}